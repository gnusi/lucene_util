Source: http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml

Use downloadTaxisCSVs.py to download each separate file (total 198 GB
as of July 2016, but I think still growing)

Each file has different headers, not normalized.  Use buildTaxisCSV.py
(single thread, many hours!) or buildTaxisCSVConcurrent.py
(multi-threaded, much faster, but chunks at the boundaries are smaller
than normal) to normalize them and concatenate to a single CSV
"chunked/block" source, total 190 GB as of July 2016.

I put the first 1M docs CSV file (35 MB gzip'd, 154 MB uncompressed)
here:

  https://drive.google.com/file/d/0Bw5IRxVmlknxQ0VIMWJCT25wU3M/view

And the first 25M docs CSV file (787 MB gzip'd, 3.8 GB uncompressed) here:

  https://drive.google.com/file/d/0Bw5IRxVmlknxZFpLaWVuQlBfTUU/view

